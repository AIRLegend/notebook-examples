{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning SDXL using DreamBooth\n",
        "**In order to use this colab upload images to a folder named `images/`**\n",
        "\n",
        "*You can upload them while the `pip install` command runs*"
      ],
      "metadata": {
        "id": "a4xFQvh3Vel4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images/"
      ],
      "metadata": {
        "id": "31trJlvzVZ-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup > setup_logs.txt"
      ],
      "metadata": {
        "id": "qcUHb5CC7jOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up hyperparameters\n",
        "After your images are uploaded, you can tune the hyperparamenters on the following cell:\n",
        "\n",
        "1. change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "2. Update prompt and remember that you must choose a very strange token for describing yourself (usually \"sks\" works).\n"
      ],
      "metadata": {
        "id": "JvMRbVLEJlZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "project_name = 'my_dreambooth_project'\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "prompt = 'photo of a sks person'\n",
        "\n",
        "# Hyperparams to play with if you want\n",
        "learning_rate = 1e-4\n",
        "num_steps = 1000\n",
        "batch_size = 1\n",
        "gradient_accumulation = 4\n",
        "resolution = 512  # can be 1024, but will be slower\n",
        "use_8bit_adam = True\n",
        "use_xformers = True\n",
        "use_fp16 = True\n",
        "train_text_encoder = False  # Will be slower, and Colab can close our session\n",
        "gradient_checkpointing = True\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(os.listdir('images/')) > 0, \"You must place your training images inside the images folder!\""
      ],
      "metadata": {
        "id": "fSFQDUa7URhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train!"
      ],
      "metadata": {
        "id": "9T0C9L8XV6G6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g3cd_ED_yXXt"
      },
      "outputs": [],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path images/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--checkpointing_steps=500 \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OYinmfPU8pmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference (generate your images)"
      ],
      "metadata": {
        "id": "QcFmMZsXV8Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir $PROJECT_NAME"
      ],
      "metadata": {
        "id": "n5vyCw1OpE6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir generations"
      ],
      "metadata": {
        "id": "0Wd6rsvYsMxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*You must upload your safetensors file to the project's folder in case you're making inference on a freshly created session (note they're destroyed once a session finishes!)*"
      ],
      "metadata": {
        "id": "M95mGGiNqDCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len([f for f in os.listdir(os.environ['PROJECT_NAME']) if '.safetensors' in f]) < 1:\n",
        "    raise RuntimeError(\"You should upload your finetuned weights to the project's folder! (the .safeternsors file)\")"
      ],
      "metadata": {
        "id": "bd9R0IRfpk2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LvIS7-7PcLT"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "import torch\n",
        "\n",
        "prj_path = \"my_dreambooth_project\"\n",
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "\n",
        "# Optionally, you can load the refiner model to improve the quality of our generations\n",
        "# Beware: Using this on regular Colab will crash it:\n",
        "#refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "#    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "#    torch_dtype=torch.float16,\n",
        "#)\n",
        "#refiner.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "generator = torch.Generator(\"cuda\")#.manual_seed(seed)"
      ],
      "metadata": {
        "id": "ALJJN3A-S5du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images_generated = 0"
      ],
      "metadata": {
        "id": "I7-3u2BnzHn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a professional LinkedIn close up photography of a sks person with a suit. Good lightning, 4k, good face.\"\n",
        "negative_prompt = 'ugly, deform, disfigured, showing teeth, blue eyes, fat, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face, blurry, draft, grainy'\n",
        "\n",
        "n_images = 10\n",
        "n_inference_steps = 100\n",
        "guidance_scale = 6.5\n",
        "\n",
        "# We generate and save images in case colab closes our session\n",
        "for i in range(n_images):\n",
        "    image = pipe(prompt=prompt,\n",
        "                generator=generator,\n",
        "                num_inference_steps=n_inference_steps,\n",
        "                guidance_scale= guidance_scale,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=1) #\n",
        "    #image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "    image.images[0].save(f\"generations/generated_image_{n_images_generated}.png\")\n",
        "    n_images_generated += 1"
      ],
      "metadata": {
        "id": "2mNaJrt688Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brJZFyysl60K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eMXaCuJXhV93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOc-bTHHiCn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: Run the refiner model to improve the quality of the generatios"
      ],
      "metadata": {
        "id": "5SM_qk_xXriz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optiona: Run the refiner model on the generated image(s) in case you loaded it!\n",
        "#seed = 42\n",
        "#generator = torch.Generator(\"cuda\")\n",
        "#orig_image = PIL.Image.open('generated_image.png')\n",
        "#image = refiner(prompt=prompt, generator=generator, image=orig_image, guidance_scale= -1, num_inference_steps=300, negative_prompt='ugly, deform, disfigured, showing teeth').images[0]"
      ],
      "metadata": {
        "id": "cVbu03-Shjv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhprTOQRj-o4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}